# -*- coding: utf-8 -*-
"""BSAN780-ContentBased-FrequencyGraphs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1voNLyQnS_0AvCWAlo5jcx8XgerHIWhJS

**Authors:** Jui Nagarkar, Injuu Jyneis, Adawn Symonette, & Jack Deveney

**Title:** BSAN 780 Final Project

**Date:** 04.02.2024

**Description:** This file contains Python code for content based filtering where we graph frequencies of top 50 unigrams and bigrams.
"""

import sqlite3
from google.colab import drive
drive.mount('/content/drive/')

conn = sqlite3.connect('/content/drive/MyDrive/BSAN 780/Music.db')
import pandas as pd

query = "SELECT TagValue FROM Tags"
df = pd.read_sql_query(query, conn)

# Display the first few rows of the DataFrame
print(df.head())

!pip install sqlite3
import sqlite3

import numpy as np
import pandas as pd
# this will allow us to connect to a SQLite database from inside Python
import sqlite3  # pip install sqlite3
# this will give us access to a function that implements the cosine similarity
from sklearn.metrics.pairwise import cosine_similarity  # pip install sklearn
# this will give us functions for Euclidean and Manhattan distances
from scipy.spatial import distance  # pip install scipy
from string import punctuation, digits
import re
import nltk
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS
from wordcloud import WordCloud
import matplotlib.pyplot as plt

conn = sqlite3.connect(r"/content/drive/MyDrive/BSAN 780/Music.db")
cur = conn.cursor()

cur.execute("SELECT TagValue FROM Tags;")

# Fetch all results from the query
docs_tuples = cur.fetchall()

# Extract the first element from each tuple to get a list of strings
docs = [doc[0] for doc in docs_tuples]

print(docs)

ps = PorterStemmer()

def preprocess_text(text):
    text = text.lower()  # make everything lowercase
    text = text.translate(str.maketrans('', '', digits))  # remove numbers
    text = text.translate(str.maketrans('', '', punctuation))  # remove punctuation
    text = re.sub(' +', ' ', text).strip()  # remove extra spaces, and spaces at the beginning and end of the string
    t_list = text.split(" ")
    text = " ".join(ps.stem(word) for word in t_list)
    return text

mystopwords = list(ENGLISH_STOP_WORDS)
mystopwords.sort()
stem_stopwords = [ps.stem(word) for word in mystopwords]


cv = CountVectorizer(preprocessor=preprocess_text,
                     ngram_range=(1, 1))

dtm = cv.fit_transform(docs)
print(len(cv.get_feature_names_out()))
print(dtm.shape)

terms = cv.get_feature_names_out()
freq_sum = dtm.sum(axis=0)[0].tolist()[0]  # this creates a list within a list so we select the first element

ctf = pd.DataFrame({"terms": terms,
                    "freq": freq_sum})
ctf.sort_values("freq", ascending=False, inplace=True)
ctf_terms = ctf.iloc[:50]["terms"].tolist()
ctf_vals = ctf.iloc[:50]["freq"].tolist()

fig = plt.figure(figsize=(10, 5))
plt.bar(ctf_terms, ctf_vals, color='blue',
        width=0.4)
plt.xticks(rotation=90)
plt.xlabel("Terms")
plt.ylabel("Frequency")
plt.title("Music Unigram CTF Top 50")
plt.show()

cv = CountVectorizer(preprocessor=preprocess_text,
                     ngram_range=(2, 2))

dtm = cv.fit_transform(docs)

terms = cv.get_feature_names_out()
freq_sum = dtm.sum(axis=0)[0].tolist()[0]  # this creates a list within a list so we select the first element

ctf = pd.DataFrame({"terms": terms,
                    "freq": freq_sum})
ctf.sort_values("freq", ascending=False, inplace=True)
ctf_terms = ctf.iloc[:50]["terms"].tolist()
ctf_vals = ctf.iloc[:50]["freq"].tolist()

fig = plt.figure(figsize=(10, 5))
plt.bar(ctf_terms, ctf_vals, color='blue',
        width=0.4)
plt.xticks(rotation=90)
plt.xlabel("Terms")
plt.ylabel("Frequency")
plt.title("Music Unigram CTF Top 50")
plt.show()